defaults:
  - base_prompt_config

# prompt_template: "{icl_example}Consider this clinical text:\n\n{clinical_sentences}\n\nDoes it make sense? If not, which sentence that is incorrect and how would you fix it?\nAnswer: {cot_prompt}"

# {icl_example}
# {clinical_sentences}
# {cot_prompt}

# Tasks

# Participants will be given a snippet of clinical text and asked to:
# Detect whether the text includes a medical error. (Binary Classification)
# Identify the text span associated with the error, if a medical error exists. (Span Identification)
# Provide a free text correction, if a medical error exists. (Natural Language Generation)

# prompt_template: "Assess the accuracy of the clinical note below. Identify any errors by their Sentence IDs. The identified sentence should be incorrect from a clinical perspective and not for reasons related to grammar or linguistic fluency. If you have identified a sentence with error, propose a corrected version of the sentence.\nOutput your response in JSON format. In the JSON object, include keys 'predicted_flags' for error presence, 'predicted_sentence_ids' for erroneous sentence indices, and 'predicted_sentences' for the corrected version of the sentence.\n\nClinical note:\n{clinical_sentences}"

prompt_template: "Assess the accuracy of the clinical note below. Each sentence in the note is prefixed by its sentence ID. If you can find an error in any of the sentences, identify the sentence containing the error by its sentence ID.\nThe identified sentence should be incorrect from a clinical perspective and not for reasons related to grammar or linguistic fluency.\nIf you have identified a sentence with error, propose a corrected version of the sentence.\nOutput your response in JSON format. In the JSON object, include keys 'error_flag' for error presence(0 if no error and 1 if there is an error), 'error_sentence_id' for erroneous sentence index, and 'corrected_sentence' for the corrected version of the sentence.\n\nClinical note:\n{clinical_sentences}"

