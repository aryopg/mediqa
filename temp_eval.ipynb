{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
      "       'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
      "       'Corrected Text', 'prompt', 'sys_prompt',\n",
      "       'factual history of patient illness', 'medical exam results',\n",
      "       'interpretation of exam results', 'diagnoses', 'treatments',\n",
      "       'Prompt for Error Sentence Detection',\n",
      "       'Sys Prompt for Error Sentence Detection', 'Identified Error Sentence'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(574, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mediqa._metrics import error_sent_identification_acc, binary_classification_acc\n",
    "\n",
    "import os\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "gpt3_annotated = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-27/annotate/09-47-02/valid_output_annotate.csv\"\n",
    "gpt4_annotated = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-27/annotate/09-59-27/valid_output_annotate.csv\"\n",
    "\n",
    "binary_res = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-27/binary/14-48-37/valid_output_binary.csv\"\n",
    "single_sent_identified_from_gpt3_annotation = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-27/identify_one_error_sentence/13-22-29/valid_output_identify_one_error_sentence.csv\"\n",
    "single_sent_identified_from_gpt4_annotation = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-27/identify_one_error_sentence/14-08-25/valid_output_identify_one_error_sentence.csv\"\n",
    "\n",
    "df = pd.read_csv(single_sent_identified_from_gpt3_annotation)\n",
    "\n",
    "# display(df.head(5))\n",
    "print(df.columns)\n",
    "df.shape\n",
    "\n",
    "# ['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
    "# 'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
    "# 'Corrected Text', 'prompt', 'sys_prompt',\n",
    "# 'factual history of patient illness', 'medical exam results',\n",
    "# 'interpretation of exam results', 'diagnoses', 'treatments',\n",
    "######\n",
    "# 'Prompt for interpretation of exam results 0',\n",
    "# 'Sys Prompt for interpretation of exam results 0',\n",
    "# 'Step-by-step Reasoning for interpretation of exam results 0',\n",
    "# 'Final Answer for interpretation of exam results 0',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30139372822299654"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = error_sent_identification_acc(df, only_incorrect_subset=False)\n",
    "# acc = error_sent_identification_acc(df, only_incorrect_subset=True)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
      "       'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
      "       'Corrected Text', 'Prompt for Error Sentence Detection',\n",
      "       'Sys Prompt for Error Sentence Detection', 'Final Answer'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(574, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(binary_res)\n",
    "print(df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4721254355400697"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = binary_classification_acc(df)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5557491289198606"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_error_sents = df[df['Error Flag']==1].shape[0]\n",
    "num_error_sents/df.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
