{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
      "       'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
      "       'Corrected Text', 'prompt', 'sys_prompt',\n",
      "       'factual history of patient illness', 'medical exam results',\n",
      "       'interpretation of exam results', 'diagnoses', 'treatments'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 16)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/data/Feb_1_2024_MS_Train_Val_Datasets/MEDIQA-CORR-2024-MS-TrainingData.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/09-30-38/annotate_output_train.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/13-00-05/detect_output_train.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/14-42-38/detect_output_train.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/14-42-38/detect_output_train-100-sampled.csv\"\n",
    "\n",
    "csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/data/Feb_1_2024_MS_Train_Val_Datasets/MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv\"\n",
    "csv_file_path =\"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/09-30-38/annotate_output_train.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/data/Feb_5_2024_UW_Validation_Set_Updated/MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv\"\n",
    "a_correct = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-22/12-58-48/detect_output_train_a_correct.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# display(df.head(5))\n",
    "print(df.columns)\n",
    "df.shape\n",
    "\n",
    "# ['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
    "# 'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
    "# 'Corrected Text', 'prompt', 'sys_prompt',\n",
    "# 'factual history of patient illness', 'medical exam results',\n",
    "# 'interpretation of exam results', 'diagnoses', 'treatments',\n",
    "######\n",
    "# 'Prompt for interpretation of exam results 0',\n",
    "# 'Sys Prompt for interpretation of exam results 0',\n",
    "# 'Step-by-step Reasoning for interpretation of exam results 0',\n",
    "# 'Final Answer for interpretation of exam results 0',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/data/Feb_1_2024_MS_Train_Val_Datasets/MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv\"\n",
    "annotated_dataset_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/09-30-38/annotate_output_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline? yes. we have to run something before doing this shit. \n",
    "\n",
    "# this shit is ust evaluating? evaluteate fgpt's abilbitye to ato aasfafdsafdafdsafdasfdjsafldafjklsa;fj\n",
    "# with mode==\n",
    "# with mode==detect. oh so we do need to run pipeline. yes. yes. we got to. \n",
    "# whwhwhattatatatatat runnign pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the idea is to do the pari combinaiton whic wawaht is it\n",
    "# what is it what is it combination com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 95)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_necessary = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-22/13-54-03/detect_output_train.csv\"\n",
    "the_best_possible = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/14-42-38/detect_output_train-100-sampled.csv\"\n",
    "an_admissable = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-22/13-35-06/detect_output_train.csv\"\n",
    "a_correct = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-22/12-58-48/detect_output_train_a_correct.csv\"\n",
    "\n",
    "qualifier_df = pd.read_csv(a_correct)\n",
    "# qualifier_df = pd.read_csv(an_admissable)\n",
    "# qualifier_df = pd.read_csv(the_best_possible)\n",
    "# qualifier_df = pd.read_csv(a_necessary)\n",
    "qualifier_df.shape\n",
    "\n",
    "# display(qualifier_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
      "       'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
      "       'Corrected Text', 'prompt', 'sys_prompt',\n",
      "       'factual history of patient illness', 'medical exam results',\n",
      "       'interpretation of exam results', 'diagnoses', 'treatments', 'prompt.1',\n",
      "       'sys_prompt.1', 'factual history of patient illness.1',\n",
      "       'medical exam results.1', 'interpretation of exam results.1',\n",
      "       'diagnoses.1', 'treatments.1',\n",
      "       'Prompt for interpretation of exam results 0',\n",
      "       'Sys Prompt for interpretation of exam results 0',\n",
      "       'Step-by-step Reasoning for interpretation of exam results 0',\n",
      "       'Final Answer for interpretation of exam results 0',\n",
      "       'Prompt for diagnoses 0', 'Sys Prompt for diagnoses 0',\n",
      "       'Step-by-step Reasoning for diagnoses 0',\n",
      "       'Final Answer for diagnoses 0', 'Prompt for treatments 0',\n",
      "       'Sys Prompt for treatments 0',\n",
      "       'Step-by-step Reasoning for treatments 0',\n",
      "       'Final Answer for treatments 0', 'Prompt for treatments 1',\n",
      "       'Sys Prompt for treatments 1',\n",
      "       'Step-by-step Reasoning for treatments 1',\n",
      "       'Final Answer for treatments 1',\n",
      "       'Prompt for interpretation of exam results 1',\n",
      "       'Sys Prompt for interpretation of exam results 1',\n",
      "       'Step-by-step Reasoning for interpretation of exam results 1',\n",
      "       'Final Answer for interpretation of exam results 1',\n",
      "       'Prompt for interpretation of exam results 2',\n",
      "       'Sys Prompt for interpretation of exam results 2',\n",
      "       'Step-by-step Reasoning for interpretation of exam results 2',\n",
      "       'Final Answer for interpretation of exam results 2',\n",
      "       'Prompt for interpretation of exam results 3',\n",
      "       'Sys Prompt for interpretation of exam results 3',\n",
      "       'Step-by-step Reasoning for interpretation of exam results 3',\n",
      "       'Final Answer for interpretation of exam results 3',\n",
      "       'Prompt for interpretation of exam results 4',\n",
      "       'Sys Prompt for interpretation of exam results 4',\n",
      "       'Step-by-step Reasoning for interpretation of exam results 4',\n",
      "       'Final Answer for interpretation of exam results 4',\n",
      "       'Prompt for diagnoses 1', 'Sys Prompt for diagnoses 1',\n",
      "       'Step-by-step Reasoning for diagnoses 1',\n",
      "       'Final Answer for diagnoses 1', 'Prompt for treatments 2',\n",
      "       'Sys Prompt for treatments 2',\n",
      "       'Step-by-step Reasoning for treatments 2',\n",
      "       'Final Answer for treatments 2', 'Prompt for diagnoses 2',\n",
      "       'Sys Prompt for diagnoses 2', 'Step-by-step Reasoning for diagnoses 2',\n",
      "       'Final Answer for diagnoses 2', 'Prompt for diagnoses 3',\n",
      "       'Sys Prompt for diagnoses 3', 'Step-by-step Reasoning for diagnoses 3',\n",
      "       'Final Answer for diagnoses 3', 'Prompt for diagnoses 4',\n",
      "       'Sys Prompt for diagnoses 4', 'Step-by-step Reasoning for diagnoses 4',\n",
      "       'Final Answer for diagnoses 4', 'Prompt for diagnoses 5',\n",
      "       'Sys Prompt for diagnoses 5', 'Step-by-step Reasoning for diagnoses 5',\n",
      "       'Final Answer for diagnoses 5', 'Prompt for treatments 3',\n",
      "       'Sys Prompt for treatments 3',\n",
      "       'Step-by-step Reasoning for treatments 3',\n",
      "       'Final Answer for treatments 3', 'Prompt for treatments 4',\n",
      "       'Sys Prompt for treatments 4',\n",
      "       'Step-by-step Reasoning for treatments 4',\n",
      "       'Final Answer for treatments 4',\n",
      "       'Prompt for interpretation of exam results 5',\n",
      "       'Sys Prompt for interpretation of exam results 5',\n",
      "       'Step-by-step Reasoning for interpretation of exam results 5',\n",
      "       'Final Answer for interpretation of exam results 5',\n",
      "       'Prompt for interpretation of exam results 6',\n",
      "       'Sys Prompt for interpretation of exam results 6',\n",
      "       'Step-by-step Reasoning for interpretation of exam results 6',\n",
      "       'Final Answer for interpretation of exam results 6'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 95)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = qualifier_df\n",
    "\n",
    "print(df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following clinical text contains factual history of patient illness, medical exam results, interpretation of exam results, diagnoses, and treatments. I want you to classify each sentence (or each parts of sentences) in the paragraph into whether they describe factual history of present illness, medical exam results, diagnoses, or treatments.\n",
      "Output your response in JSON format with keys “factual history of patient illness”, “medical exam results”, “interpretation of exam results”, “diagnoses”, and “treatments”. Note that “factual history of patient illness”, “medical exam results”, “interpretation of exam results”, “diagnoses”, and “treatments” may not appear in the original text in the said order.\n",
      "\n",
      "['A 56-year-old man comes to the emergency department because of progressively worsening shortness of breath and fever for 2 days. He also has a nonproductive cough. He does not have chest pain or headache. He has chronic myeloid leukemia and had a bone marrow transplant 3 months ago. His current medications include busulfan, mycophenolate mofetil, tacrolimus, and methylprednisolone. His temperature is 38.1 C (100.6 F), pulse is 103/min, respirations are 26/min, and blood pressure is 130/70 mm Hg. Pulse oximetry on room air shows an oxygen saturation of 93%. Pulmonary examination shows diffuse crackles. The spleen tip is palpated 4 cm below the left costal margin. Laboratory studies show:\\nHemoglobin 10.3 g/dL\\nLeukocyte count 4,400/mm3\\nPlatelet count 160,000/mm3\\nSerum\\nGlucose 78 mg/dL\\nCreatinine 2.1 mg/dL\\nD-dimer 96 ng/mL (N < 250)\\npp65 antigen positive\\nGalactomannan antigen negative\\nUrinalysis is normal. An x-ray of the chest shows diffuse bilateral interstitial infiltrates. An ECG shows sinus tachycardia. Patient was treated with ganciclovir.']\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "You are a clinician reviewing a clinical note that may or may not contain an error. Output your response in JSON format with keys “factual history of patient illness”, “medical exam results”, “interpretation of exam results”, “diagnoses”, and “treatments”.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Consider the following clinical note:\n",
      "\n",
      "['A 56-year-old man comes to the emergency department because of progressively worsening shortness of breath and fever for 2 days. He also has a nonproductive cough. He does not have chest pain or headache. He has chronic myeloid leukemia and had a bone marrow transplant 3 months ago. His current medications include busulfan, mycophenolate mofetil, tacrolimus, and methylprednisolone. His temperature is 38.1 C (100.6 F), pulse is 103/min, respirations are 26/min, and blood pressure is 130/70 mm Hg. Pulse oximetry on room air shows an oxygen saturation of 93%. Pulmonary examination shows diffuse crackles. The spleen tip is palpated 4 cm below the left costal margin. Laboratory studies show:\\nHemoglobin 10.3 g/dL\\nLeukocyte count 4,400/mm3\\nPlatelet count 160,000/mm3\\nSerum\\nGlucose 78 mg/dL\\nCreatinine 2.1 mg/dL\\nD-dimer 96 ng/mL (N < 250)\\npp65 antigen positive\\nGalactomannan antigen negative\\nUrinalysis is normal. An x-ray of the chest shows diffuse bilateral interstitial infiltrates. An ECG shows sinus tachycardia. Patient was treated with ganciclovir.']\n",
      "\n",
      "-> Was 'Chronic myeloid leukemia, progressively worsening shortness of breath, fever, nonproductive cough, diffuse bilateral interstitial infiltrates.' a correct diagnosis here? Let’s think step-by-step. Output your response in JSON format with keys “Step-by-step Reasoning” and “Final Answer”, where the value for “Final Answer” is either ‘Yes’ or ‘No’\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "The patient has a history of chronic myeloid leukemia and had a bone marrow transplant 3 months ago, putting him at risk for opportunistic infections and complications. The patient presents with progressively worsening shortness of breath, fever, nonproductive cough, diffuse crackles on pulmonary examination, and diffuse bilateral interstitial infiltrates on chest x-ray. These findings are concerning for a possible pulmonary infection or complication post bone marrow transplant. The laboratory studies do not show any significant leukocytosis, which would be expected in a patient with an acute leukemia exacerbation. Given the clinical presentation and imaging findings, a more likely diagnosis in this case would be a pulmonary infection such as pneumonia or pneumocystis jiroveci pneumonia (PJP) rather than a worsening of chronic myeloid leukemia. Therefore, 'Chronic myeloid leukemia, progressively worsening shortness of breath, fever, nonproductive cough, diffuse bilateral interstitial infiltrates' is not the correct diagnosis in this case.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "No\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "row_id = 6\n",
    "\n",
    "print(df['prompt'][row_id])\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(df['sys_prompt'][row_id])\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(df['Prompt for diagnoses 0'][row_id])\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(df['Step-by-step Reasoning for diagnoses 0'][row_id])\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "print(df['Final Answer for diagnoses 0'][row_id])\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_split_ids(indexed_sents): # cos splits aren't always based on sentences. \n",
    "    \"\"\"\n",
    "    indexed_sents: indexed sents from dataset (col 'Sentences')\n",
    "    res = tuple (id, sent)\n",
    "    \"\"\"\n",
    "    str_lst = indexed_sents.split('\\n')\n",
    "    str_lst = [item.strip() for item in str_lst]\n",
    "\n",
    "    res = [(int(item.split(' ', 1)[0]), item.split(' ', 1)[1:]) for item in str_lst]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joined_to_list(joined_sentences): # apply this func to all vals in a col. \n",
    "    category_list = joined_sentences.split('$')\n",
    "    category_list = [item.strip() for item in category_list]\n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_detected_colname(col_name: str):\n",
    "    \"\"\"\n",
    "    returns: from shit like \"Treatment 0\" to (\"treatments\", 0)\n",
    "\n",
    "    this func depends on the very specific way i named annoatated column names. \n",
    "    \"\"\"\n",
    "    categories = ['treatments', 'diagnoses', 'interpretation of exam results'] # 'medical exam results'\n",
    "    for category in categories:\n",
    "        if category in col_name:\n",
    "            return (category, int(col_name.strip()[-1]))\n",
    "        \n",
    "    return None\n",
    "\n",
    "def get_error_sent_indices(detected_df):\n",
    "    \"\"\"\n",
    "    no_columns_list: each sub list is for each row, in which tuple of columns containing No is contained. \n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list to store lists of column names\n",
    "    no_columns_list = []\n",
    "\n",
    "    # Iterate over DataFrame rows\n",
    "    for index, row in detected_df.iterrows():\n",
    "\n",
    "        no_columns_row = []\n",
    "\n",
    "        for column, value in row.items(): # col name and the value in that specific row. \n",
    "\n",
    "            if value == \"No\":\n",
    "\n",
    "                no_columns_row.append(column)\n",
    "                # print(f\"column = {column, type(column)}\") # it is what i expected. \n",
    "                \n",
    "\n",
    "        # [(\"treatments\", 0), ]\n",
    "        no_columns_row = [parse_detected_colname(item) for item in no_columns_row] if len(no_columns_row)>0 else []\n",
    "        no_columns_list.append(no_columns_row)\n",
    "\n",
    "    return no_columns_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics. -> does it make sense, with APIs especially, to have this as part of Trainer or Pipeline?\n",
    "# no. cos bs is 1. yeah that's why i had this to begin with. \n",
    "# then i guess it makes sense of compute_metrics come after each epoch rather than after each step. yes. yes. yes. \n",
    "\n",
    "def detection_eval(detected_df):\n",
    "    \"\"\"\n",
    "    use this after each epoch. well with ICL there is only one epoch right. yes. \n",
    "\n",
    "    so it CAN go into Trainer or pipeline. maybe Trainer. \n",
    "\n",
    "\n",
    "    i can see that this one includes a logic that maps prediction to that weird dataset split. \n",
    "    well this is THE eval function. should it be? how can i make this more like Harness. \n",
    "\n",
    "    well harness has doc_to_target() and a separate metrics function. \n",
    "    how is this shit different from that?\n",
    "    idk. haha. \n",
    "\n",
    "    going row by row. is this really the best? idk it doesn't take much time. why not. \n",
    "\n",
    "    I CAN log this to wandb. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    no_columns_list = get_error_sent_indices(detected_df) # list of list of tuples (rows -> multiple \"No\" detections where tuple = (category, sent_idx))\n",
    "\n",
    "    num_true_positive = 0 # if they're not detection level what are they? sentence level. \n",
    "    num_false_positive = 0 \n",
    "    false_positive_detection_level = False\n",
    "\n",
    "    row_scores = []\n",
    "\n",
    "    assert len(no_columns_list)==detected_df.shape[0], \"len(no_columns_list)!=detected_df.shape[0]\"\n",
    "\n",
    "    prev_ref_sent = \"\"\n",
    "\n",
    "    # num_correct = 0\n",
    "    no_error = False\n",
    "    for row_idx, row in enumerate(no_columns_list):\n",
    "        num_true_positive, num_false_positive = 0, 0\n",
    "        false_positive_detection_level = False\n",
    "        error_at_all = False if detected_df['Error Sentence ID'][row_idx] == -1 else True\n",
    "        if isinstance(row, list) and len(row)>0:\n",
    "            if not error_at_all:\n",
    "                false_positive_detection_level = True\n",
    "            for error_candidate in row: # (category, sent_idx)\n",
    "                category, sent_idx = error_candidate\n",
    "                str_lst = joined_to_list(detected_df[category][row_idx])\n",
    "                ref_sent = str_lst[sent_idx]\n",
    "\n",
    "                print(f\"True Error Sentence = {detected_df['Error Sentence'][row_idx]}\")\n",
    "                print(f\"ref_sent = {ref_sent}\")\n",
    "                print()\n",
    "\n",
    "                if ref_sent in str(detected_df['Error Sentence'][row_idx]): # could be nan\n",
    "                    num_true_positive +=1\n",
    "                else:\n",
    "                    num_false_positive +=1\n",
    "\n",
    "                prev_ref_sent=ref_sent\n",
    "\n",
    "        else:\n",
    "            if not error_at_all:\n",
    "                num_true_positive +=1\n",
    "                print(f\"Correctly predicted absence of error\")\n",
    "        \n",
    "        row_scores.append((error_at_all, len(row), num_true_positive, num_false_positive, false_positive_detection_level))\n",
    "\n",
    "    return row_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_list = []\n",
    "\n",
    "bool(empty_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chat_gpt_tidyed. \n",
    "\n",
    "## are these the right list of things that we might want to know?\n",
    "## is detection level really what it says it means? -> \n",
    "\n",
    "## where should this function be saved? trainer? would a lot of it change depending on the experiment config? yes. \n",
    "\n",
    "# def eval_metric_one. \n",
    "\n",
    "def evaluate_error_detection(detected_df):\n",
    "\n",
    "    no_columns_list = get_error_sent_indices(detected_df)\n",
    "    # Assert to ensure the input data is as expected\n",
    "    assert len(no_columns_list) == detected_df.shape[0], \"Length mismatch between no_columns_list and dataset size\"\n",
    "\n",
    "    row_scores = []\n",
    "\n",
    "    for row_idx, detected_errors_in_row in enumerate(no_columns_list):\n",
    "        # Initialize metrics for each row\n",
    "        num_true_positive, num_false_positive = 0, 0 # at sentence level! reset at every row. hence row_score. \n",
    "        false_positive_detection_level = False\n",
    "\n",
    "        # Check if there's supposed to be an error in the sentence\n",
    "        has_error = detected_df['Error Sentence ID'][row_idx] != -1\n",
    "\n",
    "        # If there are detected errors in the row\n",
    "        if detected_errors_in_row:\n",
    "            false_positive_detection_level = not has_error\n",
    "\n",
    "            for category, sent_idx in detected_errors_in_row:\n",
    "                # ref_sent comes from detected_df\n",
    "                ref_sent = detected_df[category][row_idx].split('$')[sent_idx].strip()  # Assuming joined_to_list is a split operation\n",
    "\n",
    "                # Check if the detected error matches the true error\n",
    "                if ref_sent in str(detected_df['Error Sentence'][row_idx]):\n",
    "                    num_true_positive += 1\n",
    "                else:\n",
    "                    num_false_positive += 1\n",
    "\n",
    "        else: # no error was detected by the model \n",
    "            # No detected errors when there shouldn't be any counts as a true positive\n",
    "            if not has_error: # ground truth label says no error. \n",
    "                num_true_positive += 1\n",
    "\n",
    "        row_scores.append((has_error, len(detected_errors_in_row), num_true_positive, num_false_positive, false_positive_detection_level))\n",
    "\n",
    "    # return row_scores\n",
    "\n",
    "\n",
    "    ## For the entire dataset\n",
    "    hit_count = 0\n",
    "    correct_count = 0\n",
    "    false_positive_detection_level_count = 0\n",
    "\n",
    "    # Iterate over the list of tuples\n",
    "    for tup in row_scores:\n",
    "        # Check if the third element of the tuple is greater than 0\n",
    "        if tup[2] > 0:\n",
    "            hit_count += 1\n",
    "\n",
    "    for tup in row_scores:\n",
    "        # Check if the third element of the tuple is greater than 0\n",
    "        if (tup[2] > 0) and (tup[3] == 0):\n",
    "            correct_count += 1\n",
    "\n",
    "    for tup in row_scores:\n",
    "        # Check if the third element of the tuple is greater than 0\n",
    "        if (tup[-1]==True):\n",
    "            false_positive_detection_level_count += 1\n",
    "\n",
    "    return {'num_rows': len(row_scores), 'num_hits': hit_count, 'num_correct': correct_count, 'num_correct_binary': len(row_scores) - false_positive_detection_level_count} # row_scores\n",
    "\n",
    "# Assuming no_columns_list and detected_df are defined elsewhere\n",
    "row_scores = evaluate_error_detection(detected_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'key123': ['lala', 'hoho']}\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_dic = {\"key123\": [\"lala\", \"hoho\"]}\n",
    "str(ex_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Error Sentence = nan\n",
      "ref_sent = Not specified in the provided text.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Dietary modification is recommended.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = No treatment information provided in the text.\n",
      "\n",
      "True Error Sentence = Dilitiazem is started after an ECG obtained during the stress test shows sinus tachycardia and ST-segment depressions in leads V1â€“V4.\n",
      "ref_sent = Dilitiazem is started.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = After reviewing labs, fresh protamine sulfate was administered to rapidly reverse this patient's coagulopathy.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Five days ago, she was admitted to the hospital and started on treatment for a deep vein thrombosis in the right leg.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Chronic myeloid leukemia, progressively worsening shortness of breath, fever, nonproductive cough, diffuse bilateral interstitial infiltrates.\n",
      "\n",
      "True Error Sentence = After obtaining imaging, patient was recommended to rest, ice, and repeat x-rays in 2 weeks.\n",
      "ref_sent = After obtaining imaging, patient was recommended to rest, ice, and repeat x-rays in 2 weeks.\n",
      "\n",
      "True Error Sentence = After obtaining imaging, patient was recommended to rest, ice, and repeat x-rays in 2 weeks.\n",
      "ref_sent = Initial X-rays of the wrist showed no abnormalities indicating no fractures or serious injury.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = Referred for CBT therapy given concern of acute stress disorder.\n",
      "ref_sent = given concern of acute stress disorder.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = Patient was diagnosed with lymphadenopathy.\n",
      "ref_sent = Patient was diagnosed with lymphadenopathy.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = nan\n",
      "ref_sent = Patient is diagnosed with diverticulosis after laboratory studies show:\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = absent fetal movements\n",
      "\n",
      "True Error Sentence = Prophylactic antibiotic therapy is needed.\n",
      "ref_sent = There are decreased breath sounds over both lung bases, indicating possible lung injury or dysfunction.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = Psoriasis is suspected.\n",
      "ref_sent = Psoriasis is suspected.\n",
      "\n",
      "True Error Sentence = Suspected of cervical spine fracture.\n",
      "ref_sent = Ultimately, the patient is discharged with follow up instructions after no significant fractures or injuries are found.\n",
      "\n",
      "True Error Sentence = Suspected of cervical spine fracture.\n",
      "ref_sent = A chest radiograph and basic labs are ordered.\n",
      "\n",
      "True Error Sentence = Staphylococcus aureus is the causal organism.\n",
      "ref_sent = Staphylococcus aureus is the causal organism.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = On physical exam, the patient is a healthy-appearing 14-year-old boy whose height is below the third percentile and whose weight is at the 50th percentile.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = Suspected of growth hormone deficiency.\n",
      "ref_sent = A laboratory workup, including thyroid stimulating hormone (TSH), is unremarkable.\n",
      "\n",
      "True Error Sentence = Patient is diagnosed with a pancreatic pseudocyst.\n",
      "ref_sent = Patient is diagnosed with a pancreatic pseudocyst.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Patient was diagnosed with Langerhans cell histiocytosis.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = He received the PPSV23 vaccine 4 years ago.\n",
      "\n",
      "True Error Sentence = Patient is diagnosed with schizotypal personality disorder.\n",
      "ref_sent = Patient is diagnosed with schizotypal personality disorder.\n",
      "\n",
      "True Error Sentence = Clonidine was prescribed.\n",
      "ref_sent = A 30-year-old man comes to the physician for follow-up evaluation for hypertension.\n",
      "\n",
      "True Error Sentence = Clonidine was prescribed.\n",
      "ref_sent = Clonidine was prescribed.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = nan\n",
      "ref_sent = No dietary changes are needed.\n",
      "\n",
      "True Error Sentence = Lithium was prescribed.\n",
      "ref_sent = major depressive disorder\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = Based on the following findings, patient was scheduled for a carotid endarterectomy.\n",
      "ref_sent = Based on the following findings, patient was scheduled for a carotid endarterectomy.\n",
      "\n",
      "True Error Sentence = Serum lipids and cholesterol were checked after physical exam was notable for a healthy young girl with no findings.\n",
      "ref_sent = uses her inhaler 1-2 times per week when she exercises\n",
      "\n",
      "True Error Sentence = MRI of brain is required.\n",
      "ref_sent = One month ago, the child was diagnosed with myopic vision.\n",
      "\n",
      "True Error Sentence = MRI of brain is required.\n",
      "ref_sent = MRI of brain is required.\n",
      "\n",
      "True Error Sentence = MRI of brain is required.\n",
      "ref_sent = The remainder of the examination shows no abnormalities.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = nan\n",
      "ref_sent = Examination shows significant weakness of the left upper and lower extremities.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = She is able to stand on her toes.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = A CT scan of the head shows no abnormalities.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = He has asthma, allergic rhinitis, and had a progressive bilateral sensorineural hearing impairment at birth treated with cochlear implants.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Arthroscopy of the left knee was scheduled after x-ray is resulted.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = An x-ray of the left knee shows no abnormalities.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = nan\n",
      "ref_sent = Not specified in the text\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = nan\n",
      "ref_sent = Patient was diagnosed with unstable angina.\n",
      "\n",
      "True Error Sentence = Recommended to limit activity to 20 minutes per day.\n",
      "ref_sent = Recommended to limit activity to 20 minutes per day\n",
      "\n",
      "True Error Sentence = Ursodeoxycholic acid is administered.\n",
      "ref_sent = Ursodeoxycholic acid is administered.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = Recommended to create food diary and outpatient follow-up. \n",
      "\n",
      "ref_sent = Recommended to create food diary and outpatient follow-up.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = She has Hashimoto thyroiditis.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Current medications include levothyroxine.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = She has tried alcohol and melatonin to help her sleep.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = She has been treated for pelvic inflammatory disease in the past.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Klebsiella granulomatis is the causal organism based on exam.\n",
      "\n",
      "True Error Sentence = Rectal suction biopsy is ordered.\n",
      "ref_sent = Rectal suction biopsy is ordered.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = nan\n",
      "ref_sent = An ECG shows sinus rhythm and a QT interval corrected for heart rate (QTc) of 470 milliseconds.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = nan\n",
      "ref_sent = The patient's symptoms and examination results suggest a diagnosis of liver disease, possibly due to Hepatitis B infection or Wilson's disease\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Elevated aspartate aminotransferase and low ceruloplasmin levels, along with the presence of Hepatitis B surface antibody and absence of Hepatitis B surface antigen, suggest liver disease\n",
      "\n",
      "True Error Sentence = Surgical excision of the nodule is scheduled. \n",
      "\n",
      "ref_sent = A PET scan that showed a nodule on the thyroid gland.\n",
      "\n",
      "True Error Sentence = Based on the following exam, an x-ray of the lumbar spine was ordered.\n",
      "ref_sent = Based on the following exam, an x-ray of the lumbar spine was ordered.\n",
      "\n",
      "True Error Sentence = In addition to intravenous administration of fluids, enteral feeding was initiated using a percutaneous endoscopic gastrostomy (PEG) tube.\n",
      "ref_sent = A CT scan of the head showed an epidural hemorrhage that was 45 cm3 in size and a midline shift of 7 mm.\n",
      "\n",
      "True Error Sentence = In addition to intravenous administration of fluids, enteral feeding was initiated using a percutaneous endoscopic gastrostomy (PEG) tube.\n",
      "ref_sent = In addition to intravenous administration of fluids, enteral feeding was initiated using a percutaneous endoscopic gastrostomy (PEG) tube.\n",
      "\n",
      "True Error Sentence = The patient is diagnosed with a tension headache.\n",
      "ref_sent = The patient is diagnosed with a tension headache.\n",
      "\n",
      "True Error Sentence = Patient is started on salmeterol twice daily.\n",
      "ref_sent = Patient is started on salmeterol twice daily.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = Levonorgestrel-releasing intrauterine device is inserted.\n",
      "ref_sent = Pelvic examination shows a firm, irregularly-shaped uterus consistent in size with a 16-week gestation.\n",
      "\n",
      "True Error Sentence = Levonorgestrel-releasing intrauterine device is inserted.\n",
      "ref_sent = Pelvic examination shows a firm, irregularly-shaped uterus consistent in size with a 16-week gestation.\n",
      "\n",
      "True Error Sentence = Levonorgestrel-releasing intrauterine device is inserted.\n",
      "ref_sent = Levonorgestrel-releasing intrauterine device is inserted.\n",
      "\n",
      "True Error Sentence = Levonorgestrel-releasing intrauterine device is inserted.\n",
      "ref_sent = The ovaries appear normal bilaterally.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = Diagnosis is chronic bronchitis.\n",
      "ref_sent = Diagnosis is chronic bronchitis.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Placenta previa is suspected.\n",
      "\n",
      "Correctly predicted absence of error\n",
      "True Error Sentence = nan\n",
      "ref_sent = After doing an ECG and labs, the patient was prescribed diltiazem for long term treatment of her symptoms.\n",
      "\n",
      "True Error Sentence = nan\n",
      "ref_sent = Serum troponins were negative on two successive blood draws and the ECG shows no abnormalities 30 minutes later.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_scores = detection_eval(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(False, 1, 0, 1, True),\n",
       " (False, 1, 0, 1, True),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 1, 0, 1, False),\n",
       " (False, 2, 0, 2, True),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 2, 1, 1, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 1, 0, 1, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 2, 0, 2, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 1, 0, 1, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 2, 1, 1, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 1, 0, 1, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 1, 0, 1, False),\n",
       " (True, 3, 1, 2, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 3, 0, 3, True),\n",
       " (False, 3, 0, 3, True),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (False, 4, 0, 4, True),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (True, 1, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 2, 0, 2, True),\n",
       " (True, 1, 0, 1, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 2, 1, 1, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 4, 1, 3, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (True, 1, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 1, 0, 1, True),\n",
       " (False, 0, 1, 0, False),\n",
       " (True, 0, 0, 0, False),\n",
       " (False, 2, 0, 2, True)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(row_scores) = 100, hit_count = 45, correct_count = 40, false_positive_detection_level_count = 21\n"
     ]
    }
   ],
   "source": [
    "# error_at_all, len(row), num_true_positive, num_false_positive, false_positive_detection_level\n",
    "\n",
    "# Initialize count\n",
    "hit_count = 0\n",
    "correct_count = 0\n",
    "false_positive_detection_level_count = 0\n",
    "\n",
    "# Iterate over the list of tuples\n",
    "for tup in row_scores:\n",
    "    # Check if the third element of the tuple is greater than 0\n",
    "    if tup[2] > 0:\n",
    "        hit_count += 1\n",
    "\n",
    "for tup in row_scores:\n",
    "    # Check if the third element of the tuple is greater than 0\n",
    "    if (tup[2] > 0) and (tup[3] == 0):\n",
    "        correct_count += 1\n",
    "\n",
    "for tup in row_scores:\n",
    "    # Check if the third element of the tuple is greater than 0\n",
    "    if (tup[-1]==True):\n",
    "        false_positive_detection_level_count += 1\n",
    "\n",
    "print(f\"len(row_scores) = {len(row_scores)}, hit_count = {hit_count}, correct_count = {correct_count}, false_positive_detection_level_count = {false_positive_detection_level_count}\")\n",
    "\n",
    "# len(row_scores) = 100, hit_count = 54, correct_count = 43, false_positive_detection_level_count = 24 -> \"best possible\"\n",
    "\n",
    "# ## the best possible\n",
    "# len(row_scores) = 100, hit_count = 54, correct_count = 43, false_positive_detection_level_count = 24\n",
    "# ## a correct\n",
    "# len(row_scores) = 100, hit_count = 45, correct_count = 40, false_positive_detection_level_count = 21\n",
    "# ## an admissible\n",
    "# len(row_scores) = 100, hit_count = 40, correct_count = 39, false_positive_detection_level_count = 19\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
