{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaeeunlee/anaconda3/envs/mediqa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import transformers\n",
    "# from trainer_qa import QuestionAnsweringTrainer\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizerFast,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "# from utils_qa import postprocess_qa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
      "       'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
      "       'Corrected Text'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(574, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/data/Feb_1_2024_MS_Train_Val_Datasets/MEDIQA-CORR-2024-MS-TrainingData.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/09-30-38/annotate_output_train.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/13-00-05/detect_output_train.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/14-42-38/detect_output_train.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/14-42-38/detect_output_train-100-sampled.csv\"\n",
    "\n",
    "csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/data/Feb_1_2024_MS_Train_Val_Datasets/MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv\"\n",
    "# csv_file_path =\"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-17/09-30-38/annotate_output_train.csv\"\n",
    "# csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/data/Feb_5_2024_UW_Validation_Set_Updated/MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv\"\n",
    "# a_correct = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/outputs/gpt3_api/2024-02-22/12-58-48/detect_output_train_a_correct.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# display(df.head(5))\n",
    "print(df.columns)\n",
    "df.shape\n",
    "\n",
    "# ['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
    "# 'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
    "# 'Corrected Text', 'prompt', 'sys_prompt',\n",
    "# 'factual history of patient illness', 'medical exam results',\n",
    "# 'interpretation of exam results', 'diagnoses', 'treatments',\n",
    "######\n",
    "# 'Prompt for interpretation of exam results 0',\n",
    "# 'Sys Prompt for interpretation of exam results 0',\n",
    "# 'Step-by-step Reasoning for interpretation of exam results 0',\n",
    "# 'Final Answer for interpretation of exam results 0',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
      "       'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
      "       'Corrected Text'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(160, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = \"/Users/chaeeunlee/Documents/VSC_workspaces/mediqa/data/Feb_5_2024_UW_Validation_Set_Updated/MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# display(df.head(5))\n",
    "print(df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = \"Which part in the given clinical note is clinically incorrect?\"\n",
    "\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Text'] = df['Text'].apply(lambda x: x[0] if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_error_span(sentence1, sentence2):\n",
    "\n",
    "    # has an error here. \n",
    "    differing_parts_sentence1 = []\n",
    "    differing_parts_sentence2 = []\n",
    "\n",
    "    if pd.isnull(sentence1):\n",
    "        sentence1_words = []\n",
    "    else:\n",
    "        sentence1_words = sentence1.split()\n",
    "\n",
    "    if pd.isnull(sentence2):\n",
    "        sentence2_words = []\n",
    "    else:\n",
    "        sentence2_words = sentence2.split()\n",
    "\n",
    "    for word in sentence1_words:\n",
    "        if word not in sentence2_words:\n",
    "            differing_parts_sentence1.append(word)\n",
    "\n",
    "    for word in sentence2_words:\n",
    "        if word not in sentence1_words:\n",
    "            differing_parts_sentence2.append(word)\n",
    "\n",
    "    return \" \".join(differing_parts_sentence1), \" \".join(differing_parts_sentence2)\n",
    "\n",
    "\n",
    "def find_error_span(sentence1, sentence2):\n",
    "    # Check if sentences are null and split them into words\n",
    "    sentence1_words = [] if pd.isnull(sentence1) else sentence1.split()\n",
    "    sentence2_words = [] if pd.isnull(sentence2) else sentence2.split()\n",
    "\n",
    "    # Initialize indices lists\n",
    "    diff_word_idx_sent1 = [idx for idx, word in enumerate(sentence1_words) if word not in sentence2_words]\n",
    "    diff_word_idx_sent2 = [idx for idx, word in enumerate(sentence2_words) if word not in sentence1_words]\n",
    "\n",
    "    # Identify contiguous differing span in sentence1\n",
    "    if diff_word_idx_sent1:\n",
    "        differing_parts_sentence1 = sentence1_words[min(diff_word_idx_sent1):max(diff_word_idx_sent1)+1]\n",
    "    else:\n",
    "        differing_parts_sentence1 = []\n",
    "\n",
    "    # Identify contiguous differing span in sentence2\n",
    "    if diff_word_idx_sent2:\n",
    "        differing_parts_sentence2 = sentence2_words[min(diff_word_idx_sent2):max(diff_word_idx_sent2)+1]\n",
    "    else:\n",
    "        differing_parts_sentence2 = []\n",
    "\n",
    "    return \" \".join(differing_parts_sentence1), \" \".join(differing_parts_sentence2)\n",
    "\n",
    "# # Example usage\n",
    "# sentence1 = \"This is an exciting example sentence.\"\n",
    "# sentence2 = \"This is a exciting sample sentence.\"\n",
    "# print(find_error_span(sentence1, sentence2))\n",
    "\n",
    "\n",
    "df['Error Span'], df['Corrected Span'] = None, None\n",
    "\n",
    "# df.loc[df['Corrected Sentence'].isna(), 'Correction'] = \"NA\"\n",
    "\n",
    "res = df.apply(lambda row: find_error_span(row['Error Sentence'], row['Corrected Sentence']), axis=1)\n",
    "# df['Correction'] = df.apply(lambda row: find_error_span(row['Error Sentence'], row['Corrected Sentence']) if pd.notnull(row['Corrected Sentence']) else None, axis=1)\n",
    "\n",
    "df['Error Span'] = res.apply(lambda x: x[0]) # the fuck is this syntax? -> ah so res is two-column df and this one's just taking the first col and adding that to df. \n",
    "df['Corrected Span'] = res.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[570, \"Error Span\"] # ''\n",
    "len(df.loc[570, \"Error Span\"]) # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subsequence 'certain subsequence' is found more than once in the text.\n",
      "Text:\n",
      "This is a sample text containing a certain subsequence and another certain subsequence.\n",
      "------------------------------------------\n",
      "The start indices of the subsequence are: [35]\n"
     ]
    }
   ],
   "source": [
    "def find_all_subsequences(text, sub_sequence, verbose=True):\n",
    "\n",
    "    if len(sub_sequence)==0:\n",
    "        return []\n",
    "        \n",
    "\n",
    "    start_indices = []\n",
    "    start_index = text.find(sub_sequence)\n",
    "    \n",
    "    while start_index != -1:\n",
    "        start_indices.append(start_index)\n",
    "        # Move the search window to look for the next occurrence\n",
    "        start_index = text.find(sub_sequence, start_index + 1)\n",
    "        \n",
    "        # Check if the subsequence is found more than twice -> more than once!\n",
    "        if len(start_indices) > 1:\n",
    "            error_msg = f\"The subsequence '{sub_sequence}' is found more than once in the text.\"\n",
    "            if verbose:\n",
    "                error_msg = error_msg + f\"\\nText:\\n{text}\" + \"\\n------------------------------------------\"\n",
    "            # raise ValueError(error_msg)\n",
    "            print(error_msg)\n",
    "\n",
    "    try:\n",
    "        res = [start_indices[0]]\n",
    "    except:\n",
    "        print(f\"hmm {sub_sequence}, {text}\")\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Example usage\n",
    "text = \"This is a sample text containing a certain subsequence and another certain subsequence.\"\n",
    "sub_sequence = \"certain subsequence\"\n",
    "\n",
    "try:\n",
    "    start_indices = find_all_subsequences(text, sub_sequence)\n",
    "    print(f\"The start indices of the subsequence are: {start_indices}\")\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need new columns: \n",
    "\n",
    "# raw_datasets = load_dataset(data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir)\n",
    "\n",
    "# import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "hf_dataset = Dataset.from_pandas(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/574 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 574/574 [00:00<00:00, 14107.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subsequence 'a disc herniation.' is found more than once in the text.\n",
      "Text:\n",
      "A 14-year-old boy is brought to the physician for the evaluation of back pain for the past six months. The pain is worse with exercise and when reclining. He attends high school and is on the swim team. He also states that he lifts weights on a regular basis. He has not had any trauma to the back or any previous problems with his joints. He has no history of serious illness. His father has a disc herniation. Palpation of the spinous processes at the lumbosacral area shows that two adjacent vertebrae are displaced and are at different levels. Muscle strength is normal. Sensation to pinprick and light touch is intact throughout. When the patient is asked to walk, a waddling gait is noted. Passive raising of either the right or left leg causes pain radiating down the ipsilateral leg. Patient was diagnosed with a disc herniation. \n",
      "------------------------------------------\n",
      "The subsequence 'The' is found more than once in the text.\n",
      "Text:\n",
      "A 21-month-old boy is brought to the physician for a well-child examination. His mother noticed deformities in both of his legs since he started walking independently. He has been healthy apart from an upper respiratory tract infection 6 months ago. He was delivered at 38 weeks' gestation. His 6-year-old sister was treated for developmental dysplasia of the hip. He can kick a ball and say a 2-word phrase. He plays well with other children at his day care. His immunizations are up-to-date. X-ray of the lower extremities was obtained. He is at the 40th percentile for height and 50th percentile for weight. Vital signs are within normal limits. Examination shows closed anterior and posterior fontanelles. The knees do not stay together when both the feet and ankles are placed together. The gait is unremarkable. The mother is concerned that he has a growth disorder. \n",
      "------------------------------------------\n",
      "The subsequence 'The' is found more than once in the text.\n",
      "Text:\n",
      "A 21-month-old boy is brought to the physician for a well-child examination. His mother noticed deformities in both of his legs since he started walking independently. He has been healthy apart from an upper respiratory tract infection 6 months ago. He was delivered at 38 weeks' gestation. His 6-year-old sister was treated for developmental dysplasia of the hip. He can kick a ball and say a 2-word phrase. He plays well with other children at his day care. His immunizations are up-to-date. X-ray of the lower extremities was obtained. He is at the 40th percentile for height and 50th percentile for weight. Vital signs are within normal limits. Examination shows closed anterior and posterior fontanelles. The knees do not stay together when both the feet and ankles are placed together. The gait is unremarkable. The mother is concerned that he has a growth disorder. \n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# answers = examples[answer_column_name][sample_index]\n",
    "# if len(answers[\"answer_start\"]) == 0:\n",
    "\n",
    "# hf_dataset['Error Span'] = \n",
    "\n",
    "# df['answers'] = df.apply(lambda row: find_all_subsequences(text=row['Text'], sub_sequence=row['Error Span']), axis=1)\n",
    "\n",
    "def transform_error_span(example):\n",
    "    original_error_span = example['Error Span']\n",
    "    return {\n",
    "        \"Answer\": {\n",
    "            \"text\": original_error_span,\n",
    "            \"answer_start\": find_all_subsequences(text=example['Text'], sub_sequence=original_error_span)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Apply the transformation to each row in the dataset\n",
    "hf_dataset = hf_dataset.map(transform_error_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag', 'Error Sentence ID', 'Error Sentence', 'Corrected Sentence', 'Corrected Text', 'question', 'Error Span', 'Corrected Span', 'Answer'],\n",
      "    num_rows: 574\n",
      "})\n",
      "[{'answer_start': [457], 'text': 'Neisseria gonorrhoeae.'}, {'answer_start': [], 'text': ''}, {'answer_start': [997], 'text': 'Streptococcus'}, {'answer_start': [436], 'text': 'a respiratory syncytial virus infection.'}, {'answer_start': [77], 'text': 'Bartonella henselae'}, {'answer_start': [], 'text': ''}, {'answer_start': [531], 'text': 'vibrio cholerae'}, {'answer_start': [], 'text': ''}, {'answer_start': [691], 'text': 'paramyxovirus.'}, {'answer_start': [], 'text': ''}, {'answer_start': [593], 'text': 'aureus.'}, {'answer_start': [], 'text': ''}, {'answer_start': [608], 'text': 'Sporothrix schenckii'}, {'answer_start': [], 'text': ''}, {'answer_start': [812], 'text': 'Mycoplasma genitalium.'}, {'answer_start': [], 'text': ''}, {'answer_start': [501], 'text': 'Anaplasma phagocytophilum'}, {'answer_start': [], 'text': ''}, {'answer_start': [585], 'text': 'Pseudomonas aeruginosa.'}, {'answer_start': [], 'text': ''}, {'answer_start': [604], 'text': 'chlamydia tachomatis'}, {'answer_start': [], 'text': ''}, {'answer_start': [503], 'text': 'Streptococcus pneumoniae.'}, {'answer_start': [], 'text': ''}, {'answer_start': [32], 'text': 'diabetic neuropathy'}, {'answer_start': [], 'text': ''}, {'answer_start': [593], 'text': 'primary ciliary dyskinesia.'}, {'answer_start': [], 'text': ''}, {'answer_start': [638], 'text': 'Whipple'}, {'answer_start': [], 'text': ''}, {'answer_start': [948], 'text': 'HELLP syndrome.'}, {'answer_start': [], 'text': ''}, {'answer_start': [586], 'text': 'Creutzfeldt-Jakob disease.'}, {'answer_start': [], 'text': ''}, {'answer_start': [731], 'text': 'acute stress disorder.'}, {'answer_start': [], 'text': ''}, {'answer_start': [307], 'text': 'serous retinopathy.'}, {'answer_start': [], 'text': ''}, {'answer_start': [563], 'text': 'extensor'}, {'answer_start': [], 'text': ''}, {'answer_start': [380], 'text': 'emphysema'}, {'answer_start': [], 'text': ''}, {'answer_start': [730], 'text': 'Turcot'}, {'answer_start': [], 'text': ''}, {'answer_start': [758], 'text': 'osteoporosis'}, {'answer_start': [], 'text': ''}, {'answer_start': [451], 'text': 'cytomegalovirus'}, {'answer_start': [], 'text': ''}, {'answer_start': [426], 'text': 'focal nodular hyperplasia.'}, {'answer_start': [], 'text': ''}, {'answer_start': [451], 'text': 'HIV encephalopathy.'}, {'answer_start': [], 'text': ''}, {'answer_start': [408], 'text': 'lymphoblastic'}, {'answer_start': [], 'text': ''}, {'answer_start': [736], 'text': 'uterine rupture.'}, {'answer_start': [], 'text': ''}, {'answer_start': [966], 'text': 'juvenile idiopathic arthritis.'}, {'answer_start': [], 'text': ''}, {'answer_start': [523], 'text': 'epidural'}, {'answer_start': [], 'text': ''}, {'answer_start': [329], 'text': 'cystoid macular edema.'}, {'answer_start': [], 'text': ''}, {'answer_start': [613], 'text': 'major'}, {'answer_start': [], 'text': ''}, {'answer_start': [37], 'text': 'VIPoma'}, {'answer_start': [], 'text': ''}, {'answer_start': [848], 'text': 'an ovarian torsion.'}, {'answer_start': [], 'text': ''}, {'answer_start': [756], 'text': 'reactive arthritis.'}, {'answer_start': [], 'text': ''}, {'answer_start': [840], 'text': 'schizophreniform disorder.'}, {'answer_start': [], 'text': ''}, {'answer_start': [772], 'text': \"patient's diagnosis is cauda equina syndrome and steroids should be started after the\"}, {'answer_start': [633], 'text': 'palatal pleomorphic adenoma.'}, {'answer_start': [], 'text': ''}, {'answer_start': [595], 'text': 'primary polydipsia.'}, {'answer_start': [], 'text': ''}, {'answer_start': [774], 'text': 'vascular dementia.'}, {'answer_start': [], 'text': ''}, {'answer_start': [758], 'text': 'lyme arthritis.'}, {'answer_start': [931], 'text': 'decompress traumatic subungual hemorrhage.'}, {'answer_start': [], 'text': ''}, {'answer_start': [800], 'text': 'serotonin'}, {'answer_start': [], 'text': ''}, {'answer_start': [762], 'text': 'X-linked agammaglobulinemia.'}, {'answer_start': [], 'text': ''}, {'answer_start': [890], 'text': 'polymyositis.'}, {'answer_start': [849], 'text': 'liver hematoma.'}, {'answer_start': [573], 'text': 'transient tachypnea'}, {'answer_start': [], 'text': ''}, {'answer_start': [798], 'text': 'intermittent explosive'}, {'answer_start': [], 'text': ''}, {'answer_start': [651], 'text': 'adenocarcinoma of the lung.'}, {'answer_start': [285], 'text': 'OCPD.'}, {'answer_start': [], 'text': ''}, {'answer_start': [727], 'text': 'uterine rupture'}, {'answer_start': [], 'text': ''}, {'answer_start': [506], 'text': 'bronchogenic cyst.'}, {'answer_start': [], 'text': ''}, {'answer_start': [875], 'text': 'measles.'}, {'answer_start': [], 'text': ''}, {'answer_start': [756], 'text': 'stenosis.'}, {'answer_start': [], 'text': ''}, {'answer_start': [711], 'text': 'scarlet fever.'}, {'answer_start': [], 'text': ''}, {'answer_start': [757], 'text': 'diabetic retinopathy.'}, {'answer_start': [], 'text': ''}, {'answer_start': [594], 'text': 'pleomorphic adenoma.'}, {'answer_start': [146], 'text': 'Colonic atresia'}, {'answer_start': [], 'text': ''}, {'answer_start': [704], 'text': 'schizophrenia.'}, {'answer_start': [406], 'text': 'Neurocardiogenic'}, {'answer_start': [], 'text': ''}, {'answer_start': [], 'text': ''}, {'answer_start': [631], 'text': 'pulmonary embolism.'}, {'answer_start': [], 'text': ''}, {'answer_start': [737], 'text': 'contact dermatitis.'}, {'answer_start': [650], 'text': 'panic disorder.'}, {'answer_start': [969], 'text': 'otosclerosis.'}, {'answer_start': [583], 'text': 'meniscus'}, {'answer_start': [], 'text': ''}, {'answer_start': [393], 'text': 'a disc herniation.'}, {'answer_start': [], 'text': ''}, {'answer_start': [538], 'text': 'central retinal artery occlusion.'}, {'answer_start': [], 'text': ''}, {'answer_start': [684], 'text': 'acute'}, {'answer_start': [258], 'text': 'fibroadenoma,'}, {'answer_start': [], 'text': ''}, {'answer_start': [611], 'text': 'bacterial vaginosis.'}, {'answer_start': [], 'text': ''}, {'answer_start': [838], 'text': 'abdominal compartment syndrome. .'}, {'answer_start': [], 'text': ''}, {'answer_start': [956], 'text': 'protein malnutrition.'}, {'answer_start': [], 'text': ''}, {'answer_start': [1126], 'text': 'minor'}, {'answer_start': [], 'text': ''}, {'answer_start': [1158], 'text': 'glioblastoma multiforme.'}, {'answer_start': [], 'text': ''}, {'answer_start': [512], 'text': 'mitral insufficiency.'}, {'answer_start': [], 'text': ''}, {'answer_start': [1154], 'text': 'acute appendicitis.'}, {'answer_start': [], 'text': ''}, {'answer_start': [451], 'text': 'x-linked ichthyosis.'}, {'answer_start': [], 'text': ''}, {'answer_start': [529], 'text': 'normal grief.'}, {'answer_start': [], 'text': ''}, {'answer_start': [603], 'text': 'somatic symptom'}, {'answer_start': [], 'text': ''}, {'answer_start': [705], 'text': 'deficiency'}, {'answer_start': [], 'text': ''}, {'answer_start': [707], 'text': 'generalized anxiety'}, {'answer_start': [], 'text': ''}, {'answer_start': [1107], 'text': 'tension pneumothorax.'}, {'answer_start': [], 'text': ''}, {'answer_start': [479], 'text': 'schizoid'}, {'answer_start': [], 'text': ''}, {'answer_start': [1123], 'text': 'nonconformity.'}, {'answer_start': [510], 'text': 'fibrocystic changes of her breasts'}, {'answer_start': [], 'text': ''}, {'answer_start': [437], 'text': 'basal'}, {'answer_start': [], 'text': ''}, {'answer_start': [318], 'text': 'CFL'}, {'answer_start': [], 'text': ''}, {'answer_start': [302], 'text': 'membranous nephropathy.'}, {'answer_start': [], 'text': ''}, {'answer_start': [543], 'text': 'holoprosencephaly'}, {'answer_start': [], 'text': ''}, {'answer_start': [], 'text': ''}, {'answer_start': [], 'text': ''}, {'answer_start': [25], 'text': 'cluster'}, {'answer_start': [], 'text': ''}, {'answer_start': [561], 'text': 'paranoid personality disorder.'}, {'answer_start': [], 'text': ''}, {'answer_start': [538], 'text': 'vein'}, {'answer_start': [], 'text': ''}, {'answer_start': [527], 'text': 'thecoma.'}, {'answer_start': [], 'text': ''}, {'answer_start': [484], 'text': 'Guillain- BarrÃ© syndrome.'}, {'answer_start': [], 'text': ''}, {'answer_start': [770], 'text': 'pyelonephritis.'}, {'answer_start': [], 'text': ''}, {'answer_start': [517], 'text': 'cholecystolithiasis'}, {'answer_start': [], 'text': ''}, {'answer_start': [966], 'text': 'Plasma exchange therapy'}, {'answer_start': [], 'text': ''}, {'answer_start': [488], 'text': 'she was recommended doing sitz baths at home.'}, {'answer_start': [], 'text': ''}, {'answer_start': [538], 'text': 'chlorhexidine hand disinfection.'}, {'answer_start': [], 'text': ''}, {'answer_start': [527], 'text': 'Blood cultures'}, {'answer_start': [804], 'text': 'Packed red blood cells are administered'}, {'answer_start': [], 'text': ''}, {'answer_start': [708], 'text': 'Endovascular thrombolysis was performed.'}, {'answer_start': [], 'text': ''}, {'answer_start': [195], 'text': 'Skin prick test for egg allergy was performed.'}, {'answer_start': [], 'text': ''}, {'answer_start': [886], 'text': 'Clomipramine is prescribed'}, {'answer_start': [429], 'text': 'Fresh frozen plasma and tranexamic acid'}, {'answer_start': [], 'text': ''}, {'answer_start': [658], 'text': 'Nuchal translucency, pregnancy-associated plasma protein-A, and human chorionic gonadotropin are'}, {'answer_start': [783], 'text': 'an antibody screening was ordered to further evaluate.'}, {'answer_start': [], 'text': ''}, {'answer_start': [796], 'text': 'oral hydroxychloroquine'}, {'answer_start': [], 'text': ''}, {'answer_start': [643], 'text': 'pyridostigmine therapy was initiated.'}, {'answer_start': [], 'text': ''}, {'answer_start': [424], 'text': 'observation.'}, {'answer_start': [541], 'text': 'topical'}, {'answer_start': [], 'text': ''}, {'answer_start': [905], 'text': 'lumbar puncture'}, {'answer_start': [], 'text': ''}, {'answer_start': [653], 'text': 'Buspirone.'}, {'answer_start': [], 'text': ''}, {'answer_start': [457], 'text': 'Quantiferon gold'}, {'answer_start': [], 'text': ''}, {'answer_start': [713], 'text': 'Plasma renin activity is measured.'}, {'answer_start': [], 'text': ''}, {'answer_start': [968], 'text': 'colonoscopy.'}, {'answer_start': [], 'text': ''}, {'answer_start': [104], 'text': 'Scrotal'}, {'answer_start': [], 'text': ''}, {'answer_start': [578], 'text': 'TMP-SMX.'}, {'answer_start': [], 'text': ''}, {'answer_start': [922], 'text': 'a digital subtraction angiography'}, {'answer_start': [], 'text': ''}, {'answer_start': [827], 'text': 'External cephalic version'}, {'answer_start': [], 'text': ''}, {'answer_start': [], 'text': ''}, {'answer_start': [], 'text': ''}, {'answer_start': [629], 'text': 'Timed doses of edrophonium were'}, {'answer_start': [369], 'text': 'Plan is delayed surgery'}, {'answer_start': [], 'text': ''}, {'answer_start': [1035], 'text': 'azithromycin'}, {'answer_start': [], 'text': ''}, {'answer_start': [540], 'text': 'hysteroscopy'}, {'answer_start': [], 'text': ''}, {'answer_start': [801], 'text': 'Supportive treatment is only required.'}, {'answer_start': [], 'text': ''}, {'answer_start': [444], 'text': 'Radiation therapy is'}, {'answer_start': [], 'text': ''}, {'answer_start': [1115], 'text': 'BiPAP was started.'}, {'answer_start': [], 'text': ''}, {'answer_start': [405], 'text': 'After the following exam, a vaginal-rectal swab was obtained for GBS culture and intravenous penicillin was administered.'}, {'answer_start': [], 'text': ''}, {'answer_start': [795], 'text': 'Dexamethasone'}, {'answer_start': [], 'text': ''}, {'answer_start': [761], 'text': 'N-acetylcysteine'}, {'answer_start': [], 'text': ''}, {'answer_start': [1056], 'text': 'sodium bicarbonate'}, {'answer_start': [464], 'text': 'Diphenhydramine'}, {'answer_start': [], 'text': ''}, {'answer_start': [890], 'text': 'Use of hot compresses'}, {'answer_start': [1358], 'text': 'aldolase levels.'}, {'answer_start': [821], 'text': 'amoxicillin.'}, {'answer_start': [544], 'text': 'A CT scan of the abdomen'}, {'answer_start': [], 'text': ''}, {'answer_start': [745], 'text': 'Observation'}, {'answer_start': [], 'text': ''}, {'answer_start': [748], 'text': 'Modified radical mastectomy is required.'}, {'answer_start': [], 'text': ''}, {'answer_start': [684], 'text': 'Supportive care'}, {'answer_start': [1117], 'text': 'exploratory laparotomy'}, {'answer_start': [], 'text': ''}, {'answer_start': [486], 'text': 'Oxytocin is prescribed.'}, {'answer_start': [], 'text': ''}, {'answer_start': [459], 'text': 'Patient is being prepared for emergent surgery.'}, {'answer_start': [], 'text': ''}, {'answer_start': [787], 'text': 'FSH and LH serum levels will be measured.'}, {'answer_start': [], 'text': ''}, {'answer_start': [1139], 'text': 'Plasma vitamin C levels were tested.'}, {'answer_start': [790], 'text': 'Surgical repair of the esophagus was performed after a Contrast'}, {'answer_start': [], 'text': ''}, {'answer_start': [579], 'text': 'fosphenytoin'}, {'answer_start': [], 'text': ''}, {'answer_start': [604], 'text': 'Arteriography'}, {'answer_start': [865], 'text': 'recommended supportive therapy including increasing fluid intake and resting.'}, {'answer_start': [504], 'text': 'Oral acyclovir is prescribed.'}, {'answer_start': [], 'text': ''}, {'answer_start': [639], 'text': 'Serum creatinine and urea nitrogen were checked to further evaluate.'}, {'answer_start': [], 'text': ''}, {'answer_start': [586], 'text': 'Pleural decortication'}, {'answer_start': [], 'text': ''}, {'answer_start': [676], 'text': 'An x-ray of the chest'}, {'answer_start': [], 'text': ''}, {'answer_start': [414], 'text': 'A thiazide diuretic was prescribed to'}, {'answer_start': [449], 'text': 'CT scan of head'}, {'answer_start': [], 'text': ''}, {'answer_start': [634], 'text': 'Prostate ultrasonography'}, {'answer_start': [], 'text': ''}, {'answer_start': [458], 'text': 'Helicobacter pylori serum IgG'}, {'answer_start': [], 'text': ''}, {'answer_start': [1057], 'text': 'Surgical decompression'}, {'answer_start': [], 'text': ''}, {'answer_start': [1015], 'text': \"patient's sister reported him to the local police after leaving the hospital.\"}, {'answer_start': [1010], 'text': 'was discontinued and azithromycin was continued to complete 7-day course.'}, {'answer_start': [688], 'text': 'metronidazole was administered.'}, {'answer_start': [], 'text': ''}, {'answer_start': [808], 'text': '0.45%'}, {'answer_start': [], 'text': ''}, {'answer_start': [652], 'text': 'transthoracic echocardiogram is ordered'}, {'answer_start': [], 'text': ''}, {'answer_start': [340], 'text': 'referred to an endocrinologist to discuss further treatment options.'}, {'answer_start': [279], 'text': 'monthly for nonstress tests beginning at 34 weeks gestation through'}, {'answer_start': [709], 'text': 'pralidoxime'}, {'answer_start': [], 'text': ''}, {'answer_start': [742], 'text': 'Technetium bone scan'}, {'answer_start': [], 'text': ''}, {'answer_start': [624], 'text': 'Mammography'}, {'answer_start': [], 'text': ''}, {'answer_start': [867], 'text': 'MRI of brain'}, {'answer_start': [], 'text': ''}, {'answer_start': [1078], 'text': 'Ethics committee was consulted to help determine the next steps.'}, {'answer_start': [887], 'text': 'Cesarean'}, {'answer_start': [450], 'text': 'Biopsy of the lesion is required.'}, {'answer_start': [], 'text': ''}, {'answer_start': [961], 'text': 'amiloride'}, {'answer_start': [], 'text': ''}, {'answer_start': [749], 'text': 'An MRI of the head was scheduled'}, {'answer_start': [], 'text': ''}, {'answer_start': [618], 'text': 'Anti-platelet'}, {'answer_start': [], 'text': ''}, {'answer_start': [199], 'text': 'cancer antigen 19-9'}, {'answer_start': [], 'text': ''}, {'answer_start': [672], 'text': 'Finasteride'}, {'answer_start': [], 'text': ''}, {'answer_start': [625], 'text': 'wedge resection of the tumor was recommended'}, {'answer_start': [], 'text': ''}, {'answer_start': [728], 'text': 'Dilation and curettage is recommended.'}, {'answer_start': [789], 'text': 'recommended stem cell transplantation.'}, {'answer_start': [], 'text': ''}, {'answer_start': [504], 'text': 'Trimethoprim/sulfamethoxazole'}, {'answer_start': [], 'text': ''}, {'answer_start': [1135], 'text': 'A paracentesis is performed.'}, {'answer_start': [521], 'text': 'Trimethoprim-sulfamethoxazole'}, {'answer_start': [661], 'text': 'Intravenous methylprednisolone'}, {'answer_start': [], 'text': ''}, {'answer_start': [829], 'text': 'A doppler ultrasound of the scrotum is ordered.'}, {'answer_start': [], 'text': ''}, {'answer_start': [796], 'text': 'a burr hole to treat a subdural hemorrhage.'}, {'answer_start': [], 'text': ''}, {'answer_start': [923], 'text': 'prolactin'}, {'answer_start': [], 'text': ''}, {'answer_start': [475], 'text': 'Repeat cytology in 6 months'}, {'answer_start': [], 'text': ''}, {'answer_start': [865], 'text': 'a percutaneous liver biopsy was recommended to further evaluate.'}, {'answer_start': [], 'text': ''}, {'answer_start': [547], 'text': 'Both parents were asked to leave the examination room to perform a forensic interivew of the child.'}, {'answer_start': [360], 'text': 'Haloperidol'}, {'answer_start': [], 'text': ''}, {'answer_start': [693], 'text': 'diagnostic laparoscopy'}, {'answer_start': [], 'text': ''}, {'answer_start': [994], 'text': 'Explorative laparotomy'}, {'answer_start': [], 'text': ''}, {'answer_start': [672], 'text': 'recommended complete bed rest and discharged home.'}, {'answer_start': [], 'text': ''}, {'answer_start': [675], 'text': 'Pelvic ultrasound is ordered.'}, {'answer_start': [], 'text': ''}, {'answer_start': [658], 'text': 'Regular echocardiographies were'}, {'answer_start': [], 'text': ''}, {'answer_start': [727], 'text': 'Measles serology was performed to confirm a measles diagnosis.'}, {'answer_start': [488], 'text': 'An enuresis alarm was recommended for the patient'}, {'answer_start': [], 'text': ''}, {'answer_start': [542], 'text': 'Detection of antistreptolysin titer'}, {'answer_start': [], 'text': ''}, {'answer_start': [459], 'text': 'X-ray of chest is ordered.'}, {'answer_start': [], 'text': ''}, {'answer_start': [1000], 'text': \"Observation and serial CT scans is the follow-up treatment for the patient's condition.\"}, {'answer_start': [594], 'text': 'Admission to hospital is required.'}, {'answer_start': [], 'text': ''}, {'answer_start': [1059], 'text': 'Evaporative cooling'}, {'answer_start': [], 'text': ''}, {'answer_start': [942], 'text': 'report the case to the authorities.'}, {'answer_start': [], 'text': ''}, {'answer_start': [815], 'text': 'Colonoscopy'}, {'answer_start': [], 'text': ''}, {'answer_start': [633], 'text': 'Recommended to refrain from administering DTaP vaccine.'}, {'answer_start': [], 'text': ''}, {'answer_start': [760], 'text': 'vancomycin'}, {'answer_start': [], 'text': ''}, {'answer_start': [316], 'text': 'Serum C-peptide concentration was measured.'}, {'answer_start': [], 'text': ''}, {'answer_start': [831], 'text': 'Rituximab'}, {'answer_start': [], 'text': ''}, {'answer_start': [544], 'text': 'fundoscopy'}, {'answer_start': [], 'text': ''}, {'answer_start': [421], 'text': 'hospital ethics committee was consulted to assist with decision making.'}, {'answer_start': [], 'text': ''}, {'answer_start': [363], 'text': 'CT scan of the abdomen and pelvis'}, {'answer_start': [], 'text': ''}, {'answer_start': [1064], 'text': 'a knee brace.'}, {'answer_start': [], 'text': ''}, {'answer_start': [911], 'text': 'reassured the patient would feel better after being hospitalized.'}, {'answer_start': [1346], 'text': 'Enalapril and aortorenal bypass with vein graft'}, {'answer_start': [599], 'text': 'Prednisone is prescribed to the patient'}, {'answer_start': [], 'text': ''}, {'answer_start': [743], 'text': 'Endoscopic biopsy of polyps is obtained.'}, {'answer_start': [686], 'text': 'patch right'}, {'answer_start': [], 'text': ''}, {'answer_start': [823], 'text': 'Vacuum-assisted delivery was performed.'}, {'answer_start': [402], 'text': 'Shampoo with zinc-pyrithone'}, {'answer_start': [], 'text': ''}, {'answer_start': [917], 'text': 'Intravenous immunoglobin'}, {'answer_start': [], 'text': ''}, {'answer_start': [710], 'text': 'The'}, {'answer_start': [], 'text': ''}, {'answer_start': [851], 'text': 'peripheral blood smear was performed.'}, {'answer_start': [], 'text': ''}, {'answer_start': [398], 'text': 'amiloride'}, {'answer_start': [], 'text': ''}, {'answer_start': [802], 'text': 'A Coombs'}, {'answer_start': [], 'text': ''}, {'answer_start': [722], 'text': 'Hysterectomy is required.'}, {'answer_start': [], 'text': ''}, {'answer_start': [691], 'text': 'single dose'}, {'answer_start': [], 'text': ''}, {'answer_start': [849], 'text': 'lumbar punture'}, {'answer_start': [], 'text': ''}, {'answer_start': [735], 'text': 'Naloxone'}, {'answer_start': [], 'text': ''}, {'answer_start': [581], 'text': 'Surgical resection and primary would closure'}, {'answer_start': [], 'text': ''}, {'answer_start': [1336], 'text': 'nyastatin mouthwash'}, {'answer_start': [], 'text': ''}, {'answer_start': [779], 'text': 'Contrast-enhanced CT angiography'}, {'answer_start': [], 'text': ''}, {'answer_start': [521], 'text': 'pantoprazole, sucralfate, and amoxicillin.'}, {'answer_start': [], 'text': ''}, {'answer_start': [378], 'text': 'Fluticasone therapy was initiated'}, {'answer_start': [392], 'text': 'Transabdominal doppler ultrasonography'}, {'answer_start': [], 'text': ''}, {'answer_start': [508], 'text': 'An IV fluid bolus is administered.'}, {'answer_start': [541], 'text': 'Laparoscopic surgical'}, {'answer_start': [], 'text': ''}, {'answer_start': [564], 'text': 'coal tar.'}, {'answer_start': [], 'text': ''}, {'answer_start': [486], 'text': 'Physical therapy was started'}, {'answer_start': [], 'text': ''}, {'answer_start': [514], 'text': 'continued observation.'}, {'answer_start': [], 'text': ''}, {'answer_start': [430], 'text': 'CTA'}, {'answer_start': [], 'text': ''}, {'answer_start': [558], 'text': 'percutaneous surgery was performed.'}, {'answer_start': [], 'text': ''}, {'answer_start': [812], 'text': 'A chest x-ray was recommended'}, {'answer_start': [], 'text': ''}, {'answer_start': [1008], 'text': 'percutaneous transluminal angioplasty'}, {'answer_start': [], 'text': ''}, {'answer_start': [538], 'text': 'Epinephrine'}, {'answer_start': [], 'text': ''}, {'answer_start': [668], 'text': 'Vaginal delivery is suggested at 38 weeks and cART is started.'}, {'answer_start': [], 'text': ''}, {'answer_start': [538], 'text': 'A CT'}, {'answer_start': [], 'text': ''}, {'answer_start': [575], 'text': 'Metoprolol'}, {'answer_start': [], 'text': ''}, {'answer_start': [474], 'text': 'surgical exploration'}, {'answer_start': [], 'text': ''}, {'answer_start': [151], 'text': '0.5-1 cm safety margins and sentinel lymph node study were'}, {'answer_start': [], 'text': ''}, {'answer_start': [894], 'text': 'stereotactic radiosurgery.'}, {'answer_start': [], 'text': ''}, {'answer_start': [534], 'text': 'Propylthiouracil therapy is initiated.'}, {'answer_start': [], 'text': ''}, {'answer_start': [872], 'text': '2:1:1'}, {'answer_start': [], 'text': ''}, {'answer_start': [814], 'text': 'tricyclic antidepressant.'}, {'answer_start': [739], 'text': 'Plasmapheresis'}, {'answer_start': [], 'text': ''}, {'answer_start': [649], 'text': 'External cephalic version'}, {'answer_start': [], 'text': ''}, {'answer_start': [562], 'text': 'Botulinum toxin injection'}, {'answer_start': [], 'text': ''}, {'answer_start': [731], 'text': 'CT scan'}, {'answer_start': [], 'text': ''}, {'answer_start': [747], 'text': 'Liver biopsy was performed.'}, {'answer_start': [], 'text': ''}, {'answer_start': [425], 'text': \"The patient's TSH level is checked.\"}, {'answer_start': [], 'text': ''}, {'answer_start': [782], 'text': 'Prostheses were removed.'}, {'answer_start': [], 'text': ''}, {'answer_start': [1101], 'text': 'interferon and ribavirin'}, {'answer_start': [718], 'text': 'Hydroxyethyl starch was administered to the patient.'}, {'answer_start': [], 'text': ''}, {'answer_start': [745], 'text': 'Fetal monitoring with continuous cardiotocography'}, {'answer_start': [], 'text': ''}, {'answer_start': [716], 'text': 'Buspirone'}, {'answer_start': [], 'text': ''}, {'answer_start': [326], 'text': 'azithromycin.'}, {'answer_start': [], 'text': ''}, {'answer_start': [583], 'text': 'theophylline.'}, {'answer_start': [], 'text': ''}, {'answer_start': [899], 'text': 'sitagliptin'}, {'answer_start': [438], 'text': 'Heparin'}, {'answer_start': [], 'text': ''}, {'answer_start': [845], 'text': 'Lorazepam'}, {'answer_start': [362], 'text': 'Corticosteroids'}, {'answer_start': [], 'text': ''}, {'answer_start': [933], 'text': 'Methylprednisolone.'}, {'answer_start': [324], 'text': 'Prothrombin complex concentrate'}, {'answer_start': [], 'text': ''}, {'answer_start': [754], 'text': 'Zolpidem'}, {'answer_start': [], 'text': ''}, {'answer_start': [574], 'text': 'Paroxetine'}, {'answer_start': [], 'text': ''}, {'answer_start': [317], 'text': 'Tamsulosin'}, {'answer_start': [], 'text': ''}, {'answer_start': [464], 'text': 'corticosteroids were'}, {'answer_start': [], 'text': ''}, {'answer_start': [324], 'text': 'Hydrochlorothiazide'}, {'answer_start': [], 'text': ''}, {'answer_start': [353], 'text': 'penicillin V'}, {'answer_start': [], 'text': ''}, {'answer_start': [485], 'text': 'Amiodarone'}, {'answer_start': [], 'text': ''}, {'answer_start': [480], 'text': 'Lorazepam'}, {'answer_start': [], 'text': ''}, {'answer_start': [569], 'text': 'nystatin,'}, {'answer_start': [], 'text': ''}, {'answer_start': [557], 'text': 'diphenhydramine'}, {'answer_start': [], 'text': ''}, {'answer_start': [446], 'text': 'carbidopa-levodopa.'}, {'answer_start': [], 'text': ''}, {'answer_start': [507], 'text': 'ondansetron.'}, {'answer_start': [], 'text': ''}, {'answer_start': [714], 'text': 'ganciclovir'}, {'answer_start': [], 'text': ''}, {'answer_start': [331], 'text': 'Ciprofloxacin'}, {'answer_start': [493], 'text': 'suvorexant.'}, {'answer_start': [500], 'text': 'ciprofloxacin'}, {'answer_start': [], 'text': ''}, {'answer_start': [980], 'text': 'Lithium'}, {'answer_start': [], 'text': ''}, {'answer_start': [587], 'text': 'oral captopril'}, {'answer_start': [], 'text': ''}, {'answer_start': [887], 'text': 'Iron supplementation'}, {'answer_start': [410], 'text': 'Pancreatic enzyme replacement'}, {'answer_start': [], 'text': ''}, {'answer_start': [603], 'text': 'abiraterone.'}, {'answer_start': [], 'text': ''}, {'answer_start': [469], 'text': 'Carbamazepine'}, {'answer_start': [710], 'text': 'Use of high SPF topical sunscreen is recommended.'}, {'answer_start': [], 'text': ''}, {'answer_start': [751], 'text': 'Magnesium was administered.'}, {'answer_start': [587], 'text': 'educated on fiber supplementation.'}, {'answer_start': [303], 'text': 'Amitriptyline'}, {'answer_start': [], 'text': ''}, {'answer_start': [547], 'text': 'ciprofloxacin.'}, {'answer_start': [], 'text': ''}, {'answer_start': [714], 'text': 'ramipril.'}, {'answer_start': [582], 'text': 'was'}, {'answer_start': [], 'text': ''}, {'answer_start': [727], 'text': 'Red blood cell transfusion'}, {'answer_start': [], 'text': ''}, {'answer_start': [520], 'text': 'doxycycline'}, {'answer_start': [], 'text': ''}, {'answer_start': [768], 'text': 'Oral vitamin A'}, {'answer_start': [], 'text': ''}, {'answer_start': [629], 'text': 'Argatroban'}, {'answer_start': [946], 'text': 'thiamine.'}, {'answer_start': [764], 'text': 'Plasmapheresis was done'}, {'answer_start': [], 'text': ''}, {'answer_start': [505], 'text': 'GABA agonist'}, {'answer_start': [], 'text': ''}, {'answer_start': [611], 'text': 'interferon-beta.'}, {'answer_start': [622], 'text': 'gentle compression with an abdominal binder'}, {'answer_start': [523], 'text': 'Methotrexate'}, {'answer_start': [], 'text': ''}, {'answer_start': [805], 'text': 'eliminate dairy from the diet.'}, {'answer_start': [], 'text': ''}, {'answer_start': [882], 'text': 'Lorazepam'}, {'answer_start': [], 'text': ''}, {'answer_start': [1238], 'text': 'omalizumab.'}, {'answer_start': [605], 'text': 'a protein-restricted diet.'}, {'answer_start': [], 'text': ''}]\n"
     ]
    }
   ],
   "source": [
    "print(hf_dataset)\n",
    "print(hf_dataset['Answer']) # {'answer_start': [], 'text': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
      "       'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
      "       'Corrected Text', 'question', 'Error Span', 'Corrected Span'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Error Flag</th>\n",
       "      <th>Error Sentence ID</th>\n",
       "      <th>Error Sentence</th>\n",
       "      <th>Corrected Sentence</th>\n",
       "      <th>Corrected Text</th>\n",
       "      <th>question</th>\n",
       "      <th>Error Span</th>\n",
       "      <th>Corrected Span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ms-val-0</td>\n",
       "      <td>A 24-year-old woman comes to the emergency department because of a 4-hour history of headaches, nausea, and vomiting. During this time, she has also had recurrent dizziness and palpitations. The symptoms started while she was at a friend's birthday party, where she had one beer. One week ago, the patient was diagnosed with a genitourinary infection and started on antimicrobial therapy. She has no history of major medical illness. Culture tests indicate Neisseria gonorrhoeae. Her pulse is 106/min and blood pressure is 102/73 mm Hg. Physical examination shows facial flushing and profuse sweating.</td>\n",
       "      <td>0 A 24-year-old woman comes to the emergency department because of a 4-hour history of headaches, nausea, and vomiting.\\n1 During this time, she has also had recurrent dizziness and palpitations.\\n2 The symptoms started while she was at a friend's birthday party, where she had one beer.\\n3 One week ago, the patient was diagnosed with a genitourinary infection and started on antimicrobial therapy.\\n4 She has no history of major medical illness.\\n5 Culture tests indicate Neisseria gonorrhoeae.\\n6 Her pulse is\\n7 106/min and blood pressure is 102/73 mm\\n8 Hg.\\n9 Physical examination shows facial flushing and profuse sweating.</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Culture tests indicate Neisseria gonorrhoeae.</td>\n",
       "      <td>Culture tests indicate Trichomonas vaginalis.</td>\n",
       "      <td>A 24-year-old woman comes to the emergency department because of a 4-hour history of headaches, nausea, and vomiting. During this time, she has also had recurrent dizziness and palpitations. The symptoms started while she was at a friend's birthday party, where she had one beer. One week ago, the patient was diagnosed with a genitourinary infection and started on antimicrobial therapy. She has no history of major medical illness. Culture tests indicate Trichomonas vaginalis. Her pulse is 106/min and blood pressure is 102/73 mm Hg. Physical examination shows facial flushing and profuse sweating.</td>\n",
       "      <td>Which part in the given clinical note is clinically incorrect?</td>\n",
       "      <td>Neisseria gonorrhoeae.</td>\n",
       "      <td>Trichomonas vaginalis.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Text ID  \\\n",
       "0           0  ms-val-0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Text  \\\n",
       "0  A 24-year-old woman comes to the emergency department because of a 4-hour history of headaches, nausea, and vomiting. During this time, she has also had recurrent dizziness and palpitations. The symptoms started while she was at a friend's birthday party, where she had one beer. One week ago, the patient was diagnosed with a genitourinary infection and started on antimicrobial therapy. She has no history of major medical illness. Culture tests indicate Neisseria gonorrhoeae. Her pulse is 106/min and blood pressure is 102/73 mm Hg. Physical examination shows facial flushing and profuse sweating.    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Sentences  \\\n",
       "0  0 A 24-year-old woman comes to the emergency department because of a 4-hour history of headaches, nausea, and vomiting.\\n1 During this time, she has also had recurrent dizziness and palpitations.\\n2 The symptoms started while she was at a friend's birthday party, where she had one beer.\\n3 One week ago, the patient was diagnosed with a genitourinary infection and started on antimicrobial therapy.\\n4 She has no history of major medical illness.\\n5 Culture tests indicate Neisseria gonorrhoeae.\\n6 Her pulse is\\n7 106/min and blood pressure is 102/73 mm\\n8 Hg.\\n9 Physical examination shows facial flushing and profuse sweating.   \n",
       "\n",
       "   Error Flag  Error Sentence ID  \\\n",
       "0           1                  5   \n",
       "\n",
       "                                  Error Sentence  \\\n",
       "0  Culture tests indicate Neisseria gonorrhoeae.   \n",
       "\n",
       "                              Corrected Sentence  \\\n",
       "0  Culture tests indicate Trichomonas vaginalis.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Corrected Text  \\\n",
       "0  A 24-year-old woman comes to the emergency department because of a 4-hour history of headaches, nausea, and vomiting. During this time, she has also had recurrent dizziness and palpitations. The symptoms started while she was at a friend's birthday party, where she had one beer. One week ago, the patient was diagnosed with a genitourinary infection and started on antimicrobial therapy. She has no history of major medical illness. Culture tests indicate Trichomonas vaginalis. Her pulse is 106/min and blood pressure is 102/73 mm Hg. Physical examination shows facial flushing and profuse sweating.    \n",
       "\n",
       "                                                         question  \\\n",
       "0  Which part in the given clinical note is clinically incorrect?   \n",
       "\n",
       "               Error Span          Corrected Span  \n",
       "0  Neisseria gonorrhoeae.  Trichomonas vaginalis.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n",
    "display(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(hf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_length,\n",
    "# data_args.doc_stride,\n",
    "# data_args.do_not_use_token_type_ids:\n",
    "\n",
    "# answer_column_name -> we have to create span column\n",
    "\n",
    "# what exactly are we giving as examples? i think it's a df? or dictionary from json. \n",
    "# train_dataset = train_dataset.map(\n",
    "#                 prepare_train_features, -> ah so it's a HF dataset. that's fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Path to directory to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
    "            \"with private models).\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "# parser = HfArgumentParser((ModelArguments,))# DataTrainingArguments, TrainingArguments))\n",
    "# if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "#     model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "# else:\n",
    "#     model_args, data_args, training_args = parser.parse_args_into_dataclasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(default=None, metadata={\"help\": \"The input training data file (a text file).\"})\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    test_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input test data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    do_not_use_token_type_ids:  bool = field(\n",
    "        default=False, metadata={\"help\": \"If true, do not use token_type_ids.\"}\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=384,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n",
    "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch (which can \"\n",
    "            \"be faster on GPU but will be slower on TPU).\"\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_predict_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    version_2_with_negative: bool = field(\n",
    "        default=False, metadata={\"help\": \"If true, some of the examples do not have an answer.\"}\n",
    "    )\n",
    "    null_score_diff_threshold: float = field(\n",
    "        default=0.0,\n",
    "        metadata={\n",
    "            \"help\": \"The threshold used to select the null answer: if the best answer has a score that is less than \"\n",
    "            \"the score of the null answer minus this threshold, the null answer is selected for this example. \"\n",
    "            \"Only useful when `version_2_with_negative=True`.\"\n",
    "        },\n",
    "    )\n",
    "    doc_stride: int = field(\n",
    "        default=128,\n",
    "        metadata={\"help\": \"When splitting up a long document into chunks, how much stride to take between chunks.\"},\n",
    "    )\n",
    "    n_best_size: int = field(\n",
    "        default=50,\n",
    "        metadata={\"help\": \"The total number of n-best predictions to generate when looking for an answer.\"},\n",
    "    )\n",
    "    max_answer_length: int = field(\n",
    "        default=30,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum length of an answer that can be generated. This is needed because the start \"\n",
    "            \"and end predictions are not conditioned on one another.\"\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "# Assuming the ModelArguments class definition is as you've provided\n",
    "\n",
    "# Now, to instantiate this class with some arguments:\n",
    "model_args = ModelArguments(\n",
    "    model_name_or_path=\"michiyasunaga/BioLinkBERT-large\",\n",
    "    config_name=\"michiyasunaga/BioLinkBERT-large\",\n",
    "    tokenizer_name=\"michiyasunaga/BioLinkBERT-large\",\n",
    "    # cache_dir='/path/to/your/cache/dir',\n",
    "    # model_revision='main',\n",
    "    # use_auth_token=True\n",
    ")\n",
    "\n",
    "data_args = DataTrainingArguments(\n",
    "    max_seq_length = 512, # 384\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args.tokenizer_name = michiyasunaga/BioLinkBERT-large\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    # cache_dir=model_args.cache_dir,\n",
    "    use_fast=True,\n",
    "    # revision=model_args.model_revision,\n",
    "    # use_auth_token=True if model_args.use_auth_token else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "max_seq_length = min(data_args.max_seq_length, tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm yea... we don't have distinction between question and context... should i just come up with a random question?\n",
    "\n",
    "question_column_name = \"question\" \n",
    "context_column_name = \"Text\" # the entire clinical text. \n",
    "\n",
    "answer_column_name = 'Answer' # print(hf_dataset['Answer']) # {'answer_start': [], 'text': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_validation_features -> determines what kind of preprocessing is needed. \n",
    "\n",
    "# Training preprocessing\n",
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[question_column_name if pad_on_right else context_column_name],\n",
    "        examples[context_column_name if pad_on_right else question_column_name], # type(examples['Text']): list\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_seq_length,\n",
    "        stride=data_args.doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\" if data_args.pad_to_max_length else False,\n",
    "    )\n",
    "    if data_args.do_not_use_token_type_ids:\n",
    "        if \"token_type_ids\" in tokenized_examples:\n",
    "            print (\"drop token_type_ids!\")\n",
    "            tokenized_examples.pop(\"token_type_ids\")\n",
    "            assert \"token_type_ids\" not in tokenized_examples\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\") # len(sample_mapping): 50 (bs)\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    # len(tokenized_examples[\"input_ids\"])\n",
    "    # 50\n",
    "    # len(tokenized_examples[\"input_ids\"][0])\n",
    "    # 384\n",
    "\n",
    "    print(f\"len(tokenized_examples['input_ids']) = {len(tokenized_examples['input_ids'])}\")\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping): # len(offset_mapping): 50 // len(offset_mapping[0]) : 384\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i] # len(tokenized_examples[\"input_ids\"][0]): 384\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[answer_column_name][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        # import pdb; pdb.set_trace()\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function prepare_train_features at 0x17f528280> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████| 574/574 [00:00<00:00, 3993.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 50\n",
      "len(tokenized_examples['input_ids']) = 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# what exactly are we giving as examples? i think it's a df? or dictionary from json. \n",
    "# train_dataset = train_dataset.map(\n",
    "#                 prepare_train_features, -> ah so it's a HF dataset. that's fine. \n",
    "\n",
    "        # with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "        #     train_dataset = train_dataset.map(\n",
    "        #         prepare_train_features,\n",
    "        #         batched=True,\n",
    "        #         num_proc=data_args.preprocessing_num_workers,\n",
    "        #         remove_columns=column_names,\n",
    "        #         load_from_cache_file=not data_args.overwrite_cache,\n",
    "        #         desc=\"Running tokenizer on train dataset\",\n",
    "        #     )\n",
    "\n",
    "mapped_hf_dataset = hf_dataset.map(prepare_train_features, batched=True, batch_size=50) # the 52 thing fixed when i changed from 384 to 512 the max seq length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SQuAD v2.0 dataset\n",
    "dataset = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.column_names\n",
    "# {'train': ['id', 'title', 'context', 'question', 'answers'],\n",
    "#  'validation': ['id', 'title', 'context', 'question', 'answers']}\n",
    "\n",
    "# dataset['train']['answers'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# row_id = 4\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m row_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m answers \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m'\u001b[39m][row_id]\n\u001b[1;32m      5\u001b[0m context \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m][row_id]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'row_id' is not defined"
     ]
    }
   ],
   "source": [
    "# row_id = 4\n",
    "row_id +=1\n",
    "\n",
    "answers = dataset['train']['answers'][row_id]\n",
    "context = dataset['train']['context'][row_id]\n",
    "\n",
    "\n",
    "start_index = context.find(answers['text'][0])\n",
    "\n",
    "print(f\"start_index = {start_index}\")\n",
    "print(f\"'answer_start' = {answers['answer_start']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some specified arguments are not used by the HfArgumentParser: ['--f=/Users/chaeeunlee/Library/Jupyter/runtime/kernel-v2-3929uGTbTULPstDI.json']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_args, data_args, training_args \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args_into_dataclasses\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mediqa/lib/python3.10/site-packages/transformers/hf_argparser.py:347\u001b[0m, in \u001b[0;36mHfArgumentParser.parse_args_into_dataclasses\u001b[0;34m(self, args, return_remaining_strings, look_for_args_file, args_filename, args_file_flag)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining_args:\n\u001b[0;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome specified arguments are not used by the HfArgumentParser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m*\u001b[39moutputs,)\n",
      "\u001b[0;31mValueError\u001b[0m: Some specified arguments are not used by the HfArgumentParser: ['--f=/Users/chaeeunlee/Library/Jupyter/runtime/kernel-v2-3929uGTbTULPstDI.json']"
     ]
    }
   ],
   "source": [
    "# model_args, data_args, training_args = parser.parse_args_into_dataclasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "#     model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "# else:\n",
    "#     model_args, data_args, training_args = parser.parse_args_into_dataclasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_train_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhf_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 48\u001b[0m, in \u001b[0;36mprepare_train_features\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     45\u001b[0m answers \u001b[38;5;241m=\u001b[39m examples[answer_column_name][sample_index]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# If no answers are given, set the cls_index as answer.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m(answers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_start\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     49\u001b[0m     tokenized_examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_positions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(cls_index)\n\u001b[1;32m     50\u001b[0m     tokenized_examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_positions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(cls_index)\n",
      "Cell \u001b[0;32mIn[31], line 48\u001b[0m, in \u001b[0;36mprepare_train_features\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     45\u001b[0m answers \u001b[38;5;241m=\u001b[39m examples[answer_column_name][sample_index]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# If no answers are given, set the cls_index as answer.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m(answers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_start\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     49\u001b[0m     tokenized_examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_positions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(cls_index)\n\u001b[1;32m     50\u001b[0m     tokenized_examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_positions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(cls_index)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mediqa/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mediqa/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = prepare_train_features(hf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_args.do_train:\n",
    "    if \"train\" not in raw_datasets:\n",
    "        raise ValueError(\"--do_train requires a train dataset\")\n",
    "    train_dataset = raw_datasets[\"train\"]\n",
    "    if data_args.max_train_samples is not None:\n",
    "        # We will select sample from whole data if agument is specified\n",
    "        train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "    # Create train feature from dataset\n",
    "    with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "        train_dataset = train_dataset.map(\n",
    "            prepare_train_features,\n",
    "            batched=True,\n",
    "            num_proc=data_args.preprocessing_num_workers,\n",
    "            remove_columns=column_names,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on train dataset\",\n",
    "        )\n",
    "    if data_args.max_train_samples is not None:\n",
    "        # Number of samples might increase during Feature Creation, We select only specified max samples\n",
    "        train_dataset = train_dataset.select(range(data_args.max_train_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
